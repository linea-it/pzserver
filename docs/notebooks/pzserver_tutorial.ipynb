{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = \"images/linea.png\" width=140 style=\"padding: 20px\"> \n",
    "<img align=\"left\" src = \"images/rubin.png\" width=180 style=\"padding: 30px\"> \n",
    "\n",
    "<font size=5> **Photo-z Server** Tutorial Notebook\n",
    " </font>\n",
    "\n",
    "Contact author: [Julia Gschwend](mailto:julia@linea.org.br) <br>\n",
    "Contributors: Luigi Silva, Cristiano Singulani <br> \n",
    "Last verified run: **2025-Jul-11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Photo-z (PZ) Server is an online service for the LSST Community to create, host and share lightweight PZ-related data products. The PZ Server is developed and maintained by LIneA as part of the in-kind contribution program (BRA-LIN) to the Rubin Observatory. The service is hosted in the Brazilian IDAC, with access restricted to the LSST Community. The access authorization is granted through [Rubin Science Platform (RSP)](https://data.lsst.cloud/) login credentials. For more information about the PZ Server and pther contribuitions related to photometric redshifts, please visit the [BRA-LIN's description page](https://linea-it.github.io/pz-lsst-inkind-doc/). \n",
    "\n",
    "The PZ Server has two main user interfaces: the website and the API, accessed via the `pzserver` Python library. \n",
    "\n",
    "This notebook contains instructuions for new users on how to use the `pzserver` Python library, with examples for all functions and methods available. The documentation on how to use the website is available on [LIneA's Documentation for Users webpage](https://docs.linea.org.br/en/sci-platforms/pz_server.html).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T15:33:33.922469Z",
     "iopub.status.busy": "2024-12-23T15:33:33.921906Z",
     "iopub.status.idle": "2024-12-23T15:33:33.926076Z",
     "shell.execute_reply": "2024-12-23T15:33:33.925435Z",
     "shell.execute_reply.started": "2024-12-23T15:33:33.922440Z"
    }
   },
   "source": [
    "<font size=5>Notebook contents </font>\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Getting Started](#getting-started) \n",
    "   - [Installation](#installation)\n",
    "   - [The PzServer class](#the-pzserver-class)\n",
    "   - [Basic methods: query general info](#basic-methods-query-general-info)\n",
    "   - [Data products: access data and display metadata](#data-products-access-data-and-display-metadata)\n",
    "   - [Sharing data products](#sharing-data-products) \n",
    "- [Data product types](#data-products)\n",
    "    - [Reference Redshift Catalog](#reference-redshift-catalog)\n",
    "    - [Training Set](#training-set)\n",
    "    - [Training Results](#training-results)\n",
    "    - [Validation Results](#validation-results)\n",
    "    - [Photo-z Estimates](#photo-z-estimates)\n",
    "- [Advanced methods](#advanced-methods)\n",
    "    - [PZ Server Pipelines](#pz-server-pipelines)\n",
    "        -  [Combine Redshift Catalogs](#combine-redshift-catalogs)\n",
    "        -  [Training Set Maker](#training-set-maker)\n",
    "    - [Upload data products via pzserver lib](#upload-data-products-via-pzserver-lib)\n",
    "    - [Update data products via pzserver lib](#update-data-products-via-pzserver-lib)\n",
    "- [User's feedback](#users-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The PZ Server's Python library is avalialble on **pip** as `pzserver`.\n",
    "\n",
    "```\n",
    "$ pip install pzserver \n",
    "```\n",
    "OBS 1: Depending on your Jupyter Notebook/Lab version, you might need to restart the kernel to incorporate the new library.\n",
    "\n",
    "OBS 2: If you are installing it on RSP Notebook Aspect on top of the LSST kernel, you might get some warnings regarding dependency versions. They must not affect the library usage. If you have any issues, please contact the [PZ Server team](mailto:julia@linea.org.br).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install pzserver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pzserver import PzServer \n",
    "#import matplotlib.pyplot as plt\n",
    "#%reload_ext autoreload \n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The PzServer class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PzServer` class object opens the connection with the PZ Server database and allows access to data and metadata. To create a `PzServer` object, users must be authorized by using an API Token which is generated in the menu at the top right corner of the [PZ Server website](https://pzserver.linea.org.br/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ScreenShotTokenMenu.png\" width=150pt align=\"top\"/> <img src=\"images/ScreenShotTokenGenerator.png\" width=350pt />\n",
    "\n",
    "Uncomment the next cell and paste the API Token, replacing the placeholder below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pz_server = PzServer(token=\"<your token here>\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API tokens can be reused indefinitely. However, an old token automatically expires whenever you create a new one. \n",
    "\n",
    "For convenience, the API token can be saved in a text file, e.g., **token.txt** (already listed in the .gitignore file in this repository). \n",
    "\n",
    "<font color=red> API tokens MUST NOT BE SHARED! Users are responsible for keeping their tokens private. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('token.txt', 'r') as file:\n",
    "#    token = file.read()\n",
    "# pz_server = PzServer(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic methods: query general info\n",
    "\n",
    "The object `pz_server` created above can provide access to data and metadata stored in the PZ Server. It also brings additional methods for users to navigate through the available content. The methods with the prefix `get_` return the result of a query on the PZ Server database as a Python dictionary and are most useful to be used programmatically (see details on the [API documentation page](https://linea-it.github.io/pzserver/html/index.html)). Alternatively, those with the prefix `display_` show the results as a styled [_Pandas DataFrames_](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), optimized for Jupyter Notebook (note: column names might change in the display version). \n",
    "\n",
    "For instance:\n",
    "\n",
    "display the list of product types supported with a short description, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.display_product_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the list of data releases available at the time, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.display_releases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and display all available data products. \n",
    "\n",
    "<font color='green'>WARNING: This list can rapidly grow during the survey's operation (cell output scrolling recommended)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pz_server.display_products_list() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about product type, users, and releases shown above can be used to filter the data products of interest for your search. For that, the method `display_products_list` receives as an argument a dictionary mapping the product's attributes to their values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pz_server.display_products_list(filters={\"release\": \"DP0.2\", \n",
    "                                         \"product_type\": \"Training Set\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also works if we type a string pattern that is part of the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pz_server.display_products_list(filters={\"product_type\": \"estimates\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch the results of a search and attribute to a variable, just change the prefix `display_` by `get_`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_results = pz_server.get_products_list(filters={\"product_type\": \"training results\"}) \n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data products: access data and display metadata\n",
    "\n",
    "<font size=4>**product_id** and **internal_name**</font>\n",
    "\n",
    "All data products stored on PZ Server are identified by its unique **product_id** number or its **internal_name**, which is created automatically at the moment of the upload by concatenating the **product_id** to the name given by its owner (replacing blank spaces by \"_\", lowering cases, and removing special characters) (e.g.: `30_simple_training_set`). \n",
    "\n",
    "<font size=4>Display the metadata of a data product</font>\n",
    "\n",
    "The metadata of a given data product is all the information available about it, including what the user provided on the upload form. \n",
    "\n",
    "The `PzServer`'s method `get_product_metadata()` returns a dictionary with the attibutes stored in the PZ Server about a given data product identified by its **id** or **internal_name**. For use in a Jupyter notebook, the equivalent `display_product_metadata()` shows the results in a formated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 30\n",
    "pz_server.display_product_metadata(product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>Download data products as .zip files*</font>\n",
    "\n",
    "To download any data product stored in the PZ Server, use the method `download_product` informing the **product_id** or **internal_name** and the path to where it will be saved (the default is the current folder). This method downloads a compressed .zip file, which contains all the files uploaded by the user, including data, auxiliary files, and description files. Let's try it with a small data product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.download_product(product_id, save_in=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>Retrieve contents of data products (work on memory)</font> \n",
    "\n",
    "\n",
    "########################################################333\n",
    "\n",
    "PAREI AQUI\n",
    "\n",
    "#############################################################\n",
    "\n",
    "\n",
    "\n",
    "Instead of downloading the files, the `pzserver` library also allows users to retrieve the contents of a given data product to work on memory using the method `get_product()`. This feature is available only for tabular data, such as redshift catalogs and training sets.\n",
    "\n",
    "By default, the method `get_product` returns an object from a particular class, depending on the product's type. The classes `SpeczCatalog` and `TrainingSet` are simple extensions of `pandas.DataFrame` (via class composition) with a couple of additional attributes and methods, such as the attribute `metadata`, and the method `display_metadata()`. Let's see an example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pz_server.get_product(2)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.display_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tabular data is allocated in the attribute `data`, a `pandas.DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(catalog.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It preserves the useful methods from `pandas.DataFrame`, such as:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who prefer working with `astropy.Table` or pure `pandas.DataFrame`, the method `get_product()` gives the flexibility to choose the output format (`fmt=\"pandas\"` or `fmt=\"astropy\"`).     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pz_server.get_product(product_id, fmt=\"pandas\")\n",
    "print(type(dataframe))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pz_server.get_product(product_id, fmt=\"astropy\")\n",
    "print(type(table))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing data products\n",
    "\n",
    "All data products uploaded to the PZ Server are immediately available and visible to all PZ Server users (people with RSP credentials) through the PZ Server website or Python library. One way to share a data product is by providing the product's URL, which leads to the product's download page. The URL is composed by the PZ Server website address + **/products/** + **internal_name**:\n",
    "\n",
    "https://pzserver.linea.org.br/product/ + **id**\n",
    "\n",
    "or \n",
    "\n",
    "https://pzserver.linea.org.br/product/ + **internal_name** \n",
    "\n",
    "<font color=green> WARNING: if still in the development phase, the URL works only with the **complete internal name**: </font> \n",
    "\n",
    "https://pzserver<font color=red>-dev</font>.linea.org.br/product/ + **internal_name**\n",
    "\n",
    "\n",
    "For example, for the data just uploaded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_name = pz_server.get_product_metadata(product_id)['internal_name']\n",
    "url = f'https://pzserver-dev.linea.org.br/product/{internal_name}'\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, let's explore specific features for each product type...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:44:23.295109Z",
     "iopub.status.busy": "2024-12-11T14:44:23.294100Z",
     "iopub.status.idle": "2024-12-11T14:44:23.394796Z",
     "shell.execute_reply": "2024-12-11T14:44:23.393752Z",
     "shell.execute_reply.started": "2024-12-11T14:44:23.295078Z"
    }
   },
   "source": [
    "# Data Products\n",
    "\n",
    "## Reference Redshift Catalog \n",
    "\n",
    "In the context of the PZ Server, Spec-z Catalogs are defined as any catalog containing spherical equatorial coordinates and spectroscopic redshift measurements (or, analogously, true redshifts from simulations). A Spec-z Catalog can include data from a single spectroscopic survey or a combination of data from several sources. To be considered a single Spec-z Catalog, the data should be provided as a single file to PZ Server's upload tool. Adding the survey name or identification as an extra column is recommended for multi-survey catalogs. \n",
    "\n",
    "\n",
    "Mandatory columns: \n",
    "* Right ascension [degrees] - `float`\n",
    "* Declination [degrees] - `float`\n",
    "* Spectroscopic or true redshift - `float`\n",
    "\n",
    "Recommended columns: \n",
    "* Spectroscopic redshift error - `float`\n",
    "* Quality flag - `integer`, `float`, or `string`\n",
    "* Survey name (recommended for compilations of data from different surveys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of Spec-z Catalog: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama = pz_server.get_product(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama.display_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama.data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `data`, which is a `DataFrame` preserves the `plot` method from Pandas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama.data.plot(x=\"RA\", y=\"DEC\", kind=\"scatter\")  \n",
    "plt.xlabel(\"R.A. (degrees)\")\n",
    "plt.ylabel(\"Dec. (degrees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama.data.hist('Z')\n",
    "plt.xlabel(\"spec-z\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.title(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T14:48:50.817530Z",
     "iopub.status.busy": "2024-12-11T14:48:50.816805Z",
     "iopub.status.idle": "2024-12-11T14:48:50.887900Z",
     "shell.execute_reply": "2024-12-11T14:48:50.886976Z",
     "shell.execute_reply.started": "2024-12-11T14:48:50.817502Z"
    }
   },
   "source": [
    "## Training Sets \n",
    "    \n",
    "In the context of the PZ Server, Training Sets are defined as the product of the spatial cross-matching between a given Spec-z Catalog (single survey or compilation) and the photometric data, in this case, the LSST Objects Catalog. The PZ Server's *Training Set Maker* pipeline allows users to build customized Training Sets based on the available Spec-z Catalogs (details below).    \n",
    "\n",
    "_Note 1: Training sets are commonly split into two or more subsets for photo-z validation purposes. If the Training Set owner has previously defined which objects should belong to each subset (training and validation/test sets), this information must be available as an extra column in the table or as clear instructions for reproducing the subset separation in the data product description._\n",
    "\n",
    "  \n",
    "_Note 2: The PZ Server only supports catalog-level Training Sets. Image-based Training Sets, e.g., for deep-learning algorithms, are not supported._\n",
    "\n",
    "\n",
    "Mandatory column: \n",
    "* Spectroscopic (or true) redshift - `float`\n",
    "\n",
    "Other expected columns\n",
    "* Object ID from LSST Objects Catalog - `integer`\n",
    "* Observables: magnitudes (and/or colors, or fluxes) from LSST Objects Catalog - `float`\n",
    "* Observable errors: magnitude errors (and/or color errors, or flux errors) from LSST Objects Catalog - `float`\n",
    "* Right ascension [degrees] - `float`\n",
    "* Declination [degrees] - `float`\n",
    "* Quality Flag - `integer`, `float`, or `string`\n",
    "* Subset Flag - `integer`, `float`, or `string`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the training set created in [RAIL's Goldenspike example notebook](https://github.com/LSSTDESC/rail/blob/main/examples/goldenspike_examples/goldenspike.ipynb): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_goldenspike = pz_server.get_product(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_goldenspike.display_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_goldenspike.data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_goldenspike.data.hist('redshift', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_goldenspike.data.hist('mag_i_lsst', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results\n",
    "\n",
    "The training results of machine learning-based PZ algorithms can also be hosted in the PZ Server to be shared and reused. This product type allows files in free format. When the training results are generated with RAIL, they are stored as *pickle* files and can be downloaded to the local work directory. \n",
    "\n",
    "OBS: The method `download_product` always brings the data as a compressed (.zip) file, regardless of the number of auxiliary files attached to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.download_product('197_goldenspike_flexzboost', save_in='.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results\n",
    "\n",
    "The PZ Server is also a good place to safely store the results of a photo-z validation procedure. Users can upload a list of files in free format, such as tabular files with photo-z estimates (single estimates and/or PDFs) of a validation set, auxiliary files with photo-z validation metrics, validation plots, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.download_product(\"11_goldenspike_flexzboost\", save_in=\".\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo-z Tables \n",
    "\n",
    "Photo-z tables are the results of a photo-z estimation procedure. If the data is larger than the file upload limit of 200MB (for instance, the PZ tables for the LSST Object catalogs delivered as part of annual data releases), the product entry stores only the metadata (and instructions on accessing the data should be provided in the description field)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Advanced methods\n",
    "\n",
    "## PZ Server Pipelines \n",
    "\n",
    "In addition to PZ-related data hosting and curation services, PZ Server also provides tools to help users prepare training data for PZ algorithms. The pipeline *Training Set Maker* uses the data partitioning method [HATS](https://hats.readthedocs.io/en/stable/) and the Python framework [LSDB](https://docs.lsdb.io/en/stable/) (both developed by [LINCC](https://lsstdiscoveryalliance.org/programs/lincc/)) as cross-matching back-end engine, coupled with a user interface on the PZ Server website plugged to the IDAC-Brazil's high-performance computing infrastructure. With *Training Set Maker*, users can create training sets by matching objects from one given spec-z catalog available in the server with objects from an LSST Object catalog. In a previous step, the spec-z catalog might have been prepared as a combination of spectroscopic redshift measurements from different sources grouped into a single catalog with the pipeline *Combine Spec-z Catalogs*. \n",
    "\n",
    "<img src=\"./images/tsm.png\" width=\"600\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Both pipelines are executed as asynchronous processes triggered from the PZ Server website or directly from Python scripts using the `pzserver` library, and the outputs are automatically registered as new data products. See below for an example of how to use them.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Spec-z Catalogs \n",
    "\n",
    "The pipeline Combine Spec-z Catalogs (CSC) simply concatenates multiple Spec-z catalogs into a single table and registers it as a new data product on the PZ Server. It was designed to help aggregate multiple samples from individual surveys into a single catalog before they are associated with LSST data through spatial cross-matching. \n",
    "\n",
    "On the PZ Server website, go to **PZ Server Pipelines** > **Combine Spec-z Catalogs**, fill in the submission form with relevant metadata, such as the name for the new spec-z catalog to be created and a short description, select the catalogs to include by marking at least two checkboxes, and press the **Run** button. \n",
    "\n",
    "\n",
    "<img src=\"./images/ScreenshotCSC.png\"  width=600 /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the pipeline can be submitted using the method `pz_server.combine_specz_catalogs` from the `pzserver` library. \n",
    "\n",
    "Start creating a \"csc\" process object instance by providing a name (string) for the new spec-z catalog to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csc = pz_server.combine_specz_catalogs(<new product's name>)\n",
    "csc = pz_server.combine_specz_catalogs(\"csc example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(csc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check status of the `csc` process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, add at least two individual spec-z catalogs to be included in the sample using the `append_catalog` method. These catalogs must already exist in the PZ Server, and their internal names identify them. Let's browse the spec-z catalogs available and choose from the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pz_server.display_products_list(filters={\"product_type\": \"Spec-z Catalog\", 'uploaded_by':'gschwend'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add those six small samples extracted from DP0.2 central tracts arbitrarily selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T15:38:18.101784Z",
     "iopub.status.busy": "2025-01-03T15:38:18.101378Z",
     "iopub.status.idle": "2025-01-03T15:38:18.107064Z",
     "shell.execute_reply": "2025-01-03T15:38:18.106024Z",
     "shell.execute_reply.started": "2025-01-03T15:38:18.101751Z"
    }
   },
   "source": [
    "<img src='./images/dpdd_dc2_zoom.png'/>\n",
    "\n",
    "Figure from: https://dp0-2.lsst.io/data-products-dp0-2/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csc = append_catalog(specz_id=None, internal_name=None)\n",
    "csc.append_catalog(213) # tract 4029\n",
    "csc.append_catalog(211) # tract 3831\n",
    "csc.append_catalog(210) # tract 4031\n",
    "csc.append_catalog(209) # tract 3448\n",
    "csc.append_catalog(208) # tract 3450\n",
    "csc.append_catalog(207) # tract 3833"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data observed with the LSST Camera become available, compilations of real data will be useful, for instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csc.append_catalog('13_vvds_specz_subsample') \n",
    "# csc.append_catalog('41_deimos_10k_public_specz') \n",
    "# csc.append_catalog('42_3dhst_public_specz') \n",
    "# csc.append_catalog('45_gama_public_specz') \n",
    "# csc.append_catalog('51_zcosmos_public_specz')\n",
    "# csc.append_catalog('52_2dflens_public_specz')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for now, let's stick with the mock data from DP0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the summary of `csc` attributes, now updated with the input catalogs added above:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the method `run` to submitt the process as an asychronous job to the PZ Server's back-end.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T20:21:59.499157Z",
     "iopub.status.busy": "2025-01-07T20:21:59.498615Z",
     "iopub.status.idle": "2025-01-07T20:21:59.595637Z",
     "shell.execute_reply": "2025-01-07T20:21:59.594385Z",
     "shell.execute_reply.started": "2025-01-07T20:21:59.499110Z"
    }
   },
   "source": [
    "Still during the process, we can check the `id` and the `internal_name` of the output data product with the `summary` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get it from the object `csc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_id = csc.output.get('id') \n",
    "catalog_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_name = csc.output.get('internal_name') \n",
    "catalog_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the process is done, if the status is 'Successful', we can move on to the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc.check_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the new spec-z catalog named as \"csc example\" is available to be downloaded or retrieved to memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_specz_catalog = pz_server.get_product(catalog_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_specz_catalog.display_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_specz_catalog.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_specz_catalog.data.plot(x=\"ra\", y=\"dec\", kind=\"scatter\")  \n",
    "plt.xlabel(\"R.A. (degrees)\")\n",
    "plt.ylabel(\"Dec. (degrees)\")\n",
    "plt.tigh_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set Maker \n",
    "\n",
    "Let's add photometric data to our spectroscopic catalog to make a training set. On the PZ Server website, go to PZ Server Pipelines > Training Set Maker, fill in the submission form with relevant metadata, such as the name for the new training set to be created and a short description, select the input data and configuration parameters, and press the Run button. \n",
    "\n",
    "The configuration parameters are inherited from LSDB. For more information, please check the [LSDB documentation website](https://docs.lsdb.io/en/stable/).  \n",
    "\n",
    "\n",
    "For this pipeline, the number of inputs is fixed to two: one spec-z catalog and one LSST Object catalog (identified by the LSST data release tag). \n",
    "\n",
    "\n",
    "<img src=\"./images/ScreenshotTSM.png\" width=600 /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the pipeline can be submitted using the `pz_server.make_training_set` method from the `pzserver` library.\n",
    "\n",
    "While waiting for the first LSST Object catalog with observed data becoming available, let's see how the *Training Set Maker* works with simulated data from DP0.2. Again, let's instantiate an object for the process, a \"tsm\" object, giving a name (string) for the new training set to be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm = pz_server.training_set_maker(\"tsm example 2\")                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set our spec-z catalog created above as input data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsm.set_specz(specz_id=None, internal_name=None)\n",
    "tsm.set_specz(catalog_id)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.display_releases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T20:57:41.713342Z",
     "iopub.status.busy": "2025-01-07T20:57:41.712591Z",
     "iopub.status.idle": "2025-01-07T20:57:41.745481Z",
     "shell.execute_reply": "2025-01-07T20:57:41.744400Z",
     "shell.execute_reply.started": "2025-01-07T20:57:41.713316Z"
    }
   },
   "source": [
    "And the data release for the object catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.set_release(name='dp02')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the configuration parameters `dict`: \n",
    "\n",
    "* The dictionary \"cross-matching\" refers to the LSDB configuration parameters `{'n_neighbors': 1, 'radius_arcsec': 1.0, 'suffixes': ['','']}`; \n",
    "* In addition, there is an extra parameter to define what to do when there are multiple matches for the same spectroscopic object: keep all matches or keep only the closest one (default). \n",
    "to be used by LSDB. \n",
    "\n",
    "```python\n",
    "tsm.set_config(                                             \n",
    "{'crossmatch': {'n_neighbors': 1, 'radius_arcsec': 1.0, 'suffixes': ['_specz','']}, 'duplicate_criteria': 'closest'}    \n",
    ")    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsm.set_config({'crossmatch': {'n_neighbors': 1, 'radius_arcsec': 1.0, 'suffixes': ['_specz','']}, 'duplicate_criteria': 'closest'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline might take longer than the previous one, so letting the notebook cell run until the process is finished is convenient instead of checking the status once in a while. For that, use the method `run_and_wait()`. \n",
    "\n",
    "OBS: the method `run_and_wait()` works if the process is shorter than 30 minutes. If it takes longer, the notebook cell is released and the process switches to the asynchronous mode.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.run_and_wait(tsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_id = tsm.output.get('id') \n",
    "training_set_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the new training set named as \"tsm example\" is available to be downloaded or retrieved to memory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set = pz_server.get_product(training_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set.display_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set.data.plot(x=\"coord_ra\", y=\"coord_dec\", kind=\"scatter\")  \n",
    "plt.xlabel(\"R.A. (degrees)\")\n",
    "plt.ylabel(\"Dec. (degrees)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set.data.hist('z_specz')\n",
    "plt.xlabel(\"spec-z\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.title(None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_training_set.data.hist('mag_i')\n",
    "plt.xlabel(\"i-band magnitude\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.title(None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload \n",
    "### How to upload a data product to PZ Server via Python API (alternative method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the default method to upload a data product to the PZ Server is the upload form on the PZ Server website. Alternatively, the `pzserver` Python library can send data products to the host service. \n",
    "\n",
    "First, prepare a dictionary with the relevant information about your data product: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_upload = {\n",
    "    \"name\":\"example upload via lib\",\n",
    "    \"product_type\": \"specz_catalog\",  # Product type \n",
    "    \"release\": None, # LSST release, use None if not LSST data \n",
    "    \"main_file\": \"upload_example.csv\", # full path \n",
    "    \"auxiliary_files\": [\"upload_example.html\", \"upload_example.ipynb\"] # full path\n",
    "    #\"auxiliary_files\": [] # you must give a empty list if you don't have any auxiliary_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = pz_server.upload(**data_to_upload)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = upload.product_id\n",
    "product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an upload object is created, you can also add auxiliary files before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload.add_auxiliary_file(\"upload_example.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save your product in PZ Server, you must give the columns names of your data. For a specz catalog, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    \"<your-RA-column-name>\": \"RA\",\n",
    "    \"<your-Dec-column-name>\": \"Dec\",\n",
    "    \"<your-z-column-name>\": \"z\"\n",
    "}\n",
    "\n",
    "upload.make_columns_association(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can finally save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "### How to edit an existing product via Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do any modification to an existing product, first you need to define the product object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = pz_server.get_product_object(product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the attributes of this product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding an auxiliary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add an auxiliary file and/or description file, given their paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.attach_auxiliary_file(path_to_auxiliary_file)\n",
    "po.attach_description_file(path_to_description_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can check if the uploads were done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.get_auxiliary_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.get_description_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also upddate the product description as shown in pzserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.update_description(\"test update description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting a single file of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete a single file of the product, you must give the file id to the ```remove_file``` method. Be careful, it is the file id, not the product id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po.remove_file(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting a full product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the product with all its files (main and auxiliary), you can use the method ```delete_product```. **BE CAREFUL! THIS CAN'T BE UNDONE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.delete_product(product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# User feedback \n",
    "\n",
    "Is something important missing? Send your feedback to us or [open an issue in the PZ Server library repository on GitHub](https://github.com/linea-it/pzserver/issues/new).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "nbsphinx": {
   "execute": "never"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9b653658693761946b8083bc5972c6593ddffeb81a0a81b81eabc816026cfc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
