{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img align=\"left\" src = https://www.linea.org.br/wp-content/themes/LIneA/imagens/logo-header.png width=100 style=\"padding: 30px\"> \n",
    "<img align=\"left\" src = https://cdn2.webdamdb.com/1280_c3PXjCZbPM23.png width=180> <!-- style=\"padding: 20px\"--> \n",
    "\n",
    "# Training Set Maker - Tutorial Notebook\n",
    "\n",
    "**Contact author**: Julia Gschwend ([julia@linea.org.br](mailto:julia@linea.org.br)) \n",
    "\n",
    "**Last verified run**: yyyy-mm-dd <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photo-z (PZ) Training Set Maker (TSM) - [pz-tsm](https://github.com/linea-it/pz-tsm) - is tool available in the PZ Server library to support the creation of Training Sets for catalog-level machine-learning-based photo-z algorithms using spec-z (or true z, for simulations) catalogs provided by the [PZ Server](https://github.com/linea-it/pz-server) and photometric data from LSST Objects Catalogs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classes para prod types - specz cat, training set (herda do pd.dataframe) \n",
    "# pz server traz objetos já na classe correspondente\n",
    "### atributos: prod id, metadata\n",
    "# tsm tem funções \n",
    "### combine specz catalogs - recebe lista de objetos specz catalogs ou lista de prod ids e criterios como argumento\n",
    "### matching - recebe 1 specz e 1 photo set (datafranme qualquer local) ou 1 prod id e 1 release tag (job remoto)\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pz_server import PzServer\n",
    "from pz_tsm import SpeczSample\n",
    "#from train_valid import TrainValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-1-560ac5ca9fe7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-560ac5ca9fe7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    -    \"Training and Validation (or Test) Sets are the product of matching (spatially) a given Spec-z Catalog (single survey or compilation) to the photometric data\u001b[0m\n\u001b[0m                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "-    \"Training and Validation (or Test) Sets are the product of matching (spatially) a given Spec-z Catalog (single survey or compilation) to the photometric data\n",
    ", in this case, the LSST Objects Catalog. In fact, in most cases, the Training and Validation Sets are just the result of splitting the product of matching into t\n",
    "wo parts. Hence, the Training and Validation Sets are usually found together. In the case of simulations, the Training and Validation Sets can be just a selection\n",
    " from the simulated catalog that contains the true redshifts and the photometric data required to train and validate the photo-z algorithms.\\n\",\n",
    "-    \"\\n\",\n",
    "-    \"In the Photo-z Server, there is no dependency between these two products. Users can upload Training and Validation Sets separately, even though they are ver\n",
    "y similar in format and contents. For each pair of Training and Validation Sets, the user will perform two uploads and, consequently, two new entries will be adde\n",
    "d to the database. \\n\",\n",
    "-    \"\\n\",\n",
    "-    \"_Note 1: There is an ambiguity between the so-called Validation and Test sets found in the literature. In some cases, it is just a matter of terminology, an\n",
    "d both play the same role: be used for computing the photo-z metrics as an independent sample from that used for training. In other cases, when the training proce\n",
    "dure has a recursive optimization method, the three sets of Training/Validation/Test are distinct, and each one plays a different role. In the context of the PZ S\n",
    "erver, there is no distiction between Validation or Test sets. The users are responsible for giving information on how to interpret the subsets on the description\n",
    " field._\\n\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('/Users/julia/github/pz-server-lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server = PzServer(token=\"b9bd517b1effa3c649f8ff092992145d44197d89\", host=\"pz-dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get basic info from PZ Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_73ab2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_73ab2_level0_col0\" class=\"col_heading level0 col0\" >product_type</th>\n",
       "      <th id=\"T_73ab2_level0_col1\" class=\"col_heading level0 col1\" >description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_73ab2_row0_col0\" class=\"data row0 col0\" >Spec-z Catalog</td>\n",
       "      <td id=\"T_73ab2_row0_col1\" class=\"data row0 col1\" >Catalog of spectroscopic redshifts and positions (usually equatorial coordinates).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_73ab2_row1_col0\" class=\"data row1 col0\" >Training Set</td>\n",
       "      <td id=\"T_73ab2_row1_col1\" class=\"data row1 col1\" >Training set for photo-z algorithms (tabular data). It usually contains magnitudes, errors, and true redshifts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_73ab2_row2_col0\" class=\"data row2 col0\" >Validation Set</td>\n",
       "      <td id=\"T_73ab2_row2_col1\" class=\"data row2 col1\" >Validation/test set for photo-z algorithms (tabular data). It usually contains magnitudes, errors, and true redshifts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_73ab2_row3_col0\" class=\"data row3 col0\" >Validation Results</td>\n",
       "      <td id=\"T_73ab2_row3_col1\" class=\"data row3 col1\" >Results of a photo-z validation procedure (free format). Usually contains photo-z estimates (single estimates and/or pdf) of a validation set and photo-z validation metrics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_73ab2_row4_col0\" class=\"data row4 col0\" >Photo-z Table</td>\n",
       "      <td id=\"T_73ab2_row4_col1\" class=\"data row4 col1\" >Results of a photo-z estimation procedure. If the data is larger than the file upload limit (200MB), the product entry stores only the metadata (instructions on accessing the data should be provided in the description field.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff5a01388b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pz_server.display_product_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.list_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.list_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.list_products_available(user=\"PZ Coord. Group\", product_type=\"specz_catalog\", release=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spec-z Catalog \n",
    "#### 1.1 List Spec-z Catalogs available on Pz Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz_server.list_products_available(user=\"PZ Coord. Group\", product_type=\"specz_catalog\", release=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Get metadata of a list of Spec-z Catalogs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_specz_1 = PzServer.get_product_metadata(product_id=\"0001\")\n",
    "metadata_specz_1  # markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_specz_2 = PzServer.get_product_metadata(product_id=\"0002\")\n",
    "metadata_specz_2  # markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_specz_3 = PzServer.get_product_metadata(product_id=\"0003\")\n",
    "metadata_specz_3  # markdown table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create a single Spec-z Sample from a single Spec-z Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_one = SpeczSample(catalogs=[\"0001\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_one.metadata # metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_one.data # dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filters on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: pandas query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include info about filters used in the readme txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file with filtered spec-z sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_one.save_file() # save 2 files (data and readme), ready to upload on PZ Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Create a single Spec-z Sample from a list of Spec-z Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_all = SpeczSample(catalogs=[\"0001\", \"0002\", \"0003\"], resolve_multiple=\"keep all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_best = SpeczSample(catalogs=[\"0001\", \"0002\", \"0003\"], resolve_multiple=\"best\") # best flag, then smallest error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_newest = SpeczSample(catalogs=[\"0001\", \"0002\", \"0003\"], resolve_multiple=\"newest\") # newest survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_best.metadata # combined metadata (markdown table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_best.data # dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filters on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: pandas query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file with filtered spec-z sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specz_sample_best.save_file(file_format=\"parquet\") # save 2 files (data and readme(json)), ready to upload on PZ Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini QA of combined Spec-z Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Validation Sets\n",
    "\n",
    "The training and Validation Sets are build as the combination of a Spec-z Sample (a Spec-z Sample object as defined above, or a Spec-z Catalog data product retrieved from the PZ Server) and photometric data retrieved from the API aspect of RSP.   \n",
    "\n",
    "(to do: include case for 3 subsets (train/valid/test)\n",
    "#### 2.1 Create Training and Validation Sets from a Spec-z Sample object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=\"random\"\n",
    "train_fraction=0.7 # use 1.0 or 0.0 to create training set or validation set separately\n",
    "observables=[\"mag_u\", \"mag_g\", \"mag_r\", \"mag_i\", \"mag_z\", \"mag_y\", \n",
    "             \"magerr_u\", \"magerr_g\", \"magerr_r\", \"magerr_i\", \"magerr_z\", \"magerr_y\"] # any list of columns from LSST objects catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz = TrainValid(specz_sample_best, split=split, train_fraction=train_fraction, observables=observables)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz.train_metadata # markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz.train_data # dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz.valid_metadata # markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz.valid_data  # dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini QA of Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_local_specz.save_file(file_format=\"parquet\")  # save 4 files (2 data and 2 readme (json)), ready to upload on PZ Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create Training and Validation Sets from a Spec-z Catalog data product in PZ Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_remote_specz = TrainValid(\"0001\", split=split, train_fraction=train_fraction, observables=observables)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_remote_specz.train_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_remote_specz.train_data # dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_remote_specz.valid_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_remote_specz.valid_data  # dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini QA of Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9b653658693761946b8083bc5972c6593ddffeb81a0a81b81eabc816026cfc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
